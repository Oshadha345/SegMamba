{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2534ebb6",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f188472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(\"/storage2/CV_Irradiance/VMamba/BRTM\")\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Working Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b877e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Custom modules\n",
    "from config import Config\n",
    "from models import SegMamba\n",
    "from data import create_dataloaders\n",
    "from utils import ExperimentManager, visualize_batch\n",
    "from train import SegMambaTrainer\n",
    "\n",
    "print(\"‚úì All imports successful\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91866bbb",
   "metadata": {},
   "source": [
    "### üéØ Configuration\n",
    "\n",
    "**IMPORTANT**: Change `RUN_NAME` for each training run to avoid overwriting results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - MODIFY THIS SECTION FOR EACH RUN\n",
    "# =============================================================================\n",
    "\n",
    "# Experiment name (CHANGE THIS FOR EACH NEW RUN!)\n",
    "Config.RUN_NAME = \"SegMamba_Run01\"\n",
    "Config.DESCRIPTION = \"Pure Mamba SegMamba baseline\"\n",
    "\n",
    "# Model architecture\n",
    "Config.PATCH_SIZE = (128, 128, 64)  # Adjust based on GPU VRAM\n",
    "Config.BASE_CHANNELS = 32\n",
    "\n",
    "# Training hyperparameters\n",
    "Config.BATCH_SIZE = 2\n",
    "Config.ACCUMULATION_STEPS = 2\n",
    "Config.NUM_EPOCHS = 300\n",
    "Config.INITIAL_LR = 1e-4\n",
    "\n",
    "# Data paths (UPDATE TO YOUR DATASET LOCATION)\n",
    "Config.DATA_ROOT = Path(\"/storage2/CV_Irradiance/datasets/CVMD/BraTS\")\n",
    "Config.TRAIN_DATA_PATH = Config.DATA_ROOT / \"train\"\n",
    "Config.VAL_DATA_PATH = Config.DATA_ROOT / \"val\"\n",
    "\n",
    "# Results path\n",
    "Config.RESULTS_BASE_PATH = project_root / \"results\"\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "# Print configuration\n",
    "Config.print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f7b67",
   "metadata": {},
   "source": [
    "## 2. Data Verification\n",
    "\n",
    "Verify dataset structure and accessibility before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data paths exist\n",
    "print(\"=\" * 70)\n",
    "print(\"Data Path Verification\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nDATA_ROOT: {Config.DATA_ROOT}\")\n",
    "print(f\"Exists: {Config.DATA_ROOT.exists()}\")\n",
    "\n",
    "print(f\"\\nTRAIN_DATA_PATH: {Config.TRAIN_DATA_PATH}\")\n",
    "print(f\"Exists: {Config.TRAIN_DATA_PATH.exists()}\")\n",
    "\n",
    "print(f\"\\nVAL_DATA_PATH: {Config.VAL_DATA_PATH}\")\n",
    "print(f\"Exists: {Config.VAL_DATA_PATH.exists()}\")\n",
    "\n",
    "# List sample patients\n",
    "if Config.TRAIN_DATA_PATH.exists():\n",
    "    train_patients = [d for d in Config.TRAIN_DATA_PATH.iterdir() if d.is_dir()]\n",
    "    print(f\"\\nNumber of training patients: {len(train_patients)}\")\n",
    "    if len(train_patients) > 0:\n",
    "        print(f\"Sample patients: {[p.name for p in train_patients[:5]]}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: Training data path does not exist!\")\n",
    "    print(\"Please update Config.DATA_ROOT in the configuration cell above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a1e96",
   "metadata": {},
   "source": [
    "## 3. Initialize Experiment Manager\n",
    "\n",
    "This ensures no overwriting between training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d2b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize experiment manager\n",
    "try:\n",
    "    exp_manager = ExperimentManager(\n",
    "        run_name=Config.RUN_NAME,\n",
    "        base_path=str(Config.RESULTS_BASE_PATH),\n",
    "        overwrite=False  # Set True to overwrite existing run\n",
    "    )\n",
    "    \n",
    "    # Save configuration\n",
    "    exp_manager.save_config(Config.get_config_dict())\n",
    "    \n",
    "    print(f\"‚úì Experiment initialized: {exp_manager.run_path}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"1. Change Config.RUN_NAME to a new name\")\n",
    "    print(\"2. Set overwrite=True (WARNING: deletes existing results)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c253cb6",
   "metadata": {},
   "source": [
    "## 4. Create Data Loaders\n",
    "\n",
    "Load BraTS dataset with MONAI transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Creating Data Loaders\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    train_loader, val_loader = create_dataloaders(\n",
    "        train_data_path=str(Config.TRAIN_DATA_PATH),\n",
    "        val_data_path=str(Config.VAL_DATA_PATH),\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        patch_size=Config.PATCH_SIZE,\n",
    "        num_workers=Config.NUM_WORKERS,\n",
    "        pin_memory=Config.PIN_MEMORY\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úì Data loaders created successfully\")\n",
    "    print(f\"Training batches: {len(train_loader)}\")\n",
    "    print(f\"Validation batches: {len(val_loader)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating data loaders: {e}\")\n",
    "    print(\"\\nPossible solutions:\")\n",
    "    print(\"1. Verify dataset structure matches BraTS format\")\n",
    "    print(\"2. Check file permissions\")\n",
    "    print(\"3. Install MONAI: pip install monai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc87fd55",
   "metadata": {},
   "source": [
    "## 5. Visualize Sample Batch\n",
    "\n",
    "Sanity check: visualize a sample batch before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Sample Batch Information:\")\n",
    "print(f\"Image shape: {sample_batch['image'].shape}\")\n",
    "print(f\"Label shape: {sample_batch['label'].shape}\")\n",
    "print(f\"Image dtype: {sample_batch['image'].dtype}\")\n",
    "print(f\"Label dtype: {sample_batch['label'].dtype}\")\n",
    "print(f\"Image range: [{sample_batch['image'].min():.3f}, {sample_batch['image'].max():.3f}]\")\n",
    "print(f\"Label unique values: {torch.unique(sample_batch['label']).tolist()}\")\n",
    "\n",
    "# Visualize\n",
    "save_path = exp_manager.get_plot_path(\"notebook_sample_batch.png\")\n",
    "visualize_batch(\n",
    "    images=sample_batch['image'],\n",
    "    labels=sample_batch['label'],\n",
    "    save_path=save_path,\n",
    "    title=\"Sample Training Batch\"\n",
    ")\n",
    "\n",
    "# Display in notebook\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=str(save_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57953252",
   "metadata": {},
   "source": [
    "## 6. Initialize Model\n",
    "\n",
    "Create SegMamba architecture and verify forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Initializing SegMamba Model\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "model = SegMamba(\n",
    "    in_channels=Config.IN_CHANNELS,\n",
    "    num_classes=Config.NUM_CLASSES,\n",
    "    base_channels=Config.BASE_CHANNELS,\n",
    "    encoder_depths=Config.ENCODER_DEPTHS,\n",
    "    use_checkpoint=Config.USE_CHECKPOINT\n",
    ").to(Config.DEVICE)\n",
    "\n",
    "print(f\"\\n‚úì Model initialized\")\n",
    "print(f\"Total parameters: {model.count_parameters():,}\")\n",
    "print(f\"Model on device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nTesting forward pass...\")\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(1, Config.IN_CHANNELS, *Config.PATCH_SIZE).to(Config.DEVICE)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"‚úì Forward pass successful\")\n",
    "    print(f\"  Input shape: {test_input.shape}\")\n",
    "    print(f\"  Output shape: {test_output.shape}\")\n",
    "    \n",
    "    # Memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        memory_allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "        memory_reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "        print(f\"  GPU Memory Allocated: {memory_allocated:.2f} GB\")\n",
    "        print(f\"  GPU Memory Reserved: {memory_reserved:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da00551",
   "metadata": {},
   "source": [
    "## 7. Initialize Trainer\n",
    "\n",
    "Create trainer with all components: optimizer, scheduler, loss, metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Initializing Trainer\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "trainer = SegMambaTrainer(\n",
    "    config=Config,\n",
    "    experiment_manager=exp_manager\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Trainer initialized\")\n",
    "print(f\"Optimizer: {Config.OPTIMIZER}\")\n",
    "print(f\"Learning rate: {Config.INITIAL_LR}\")\n",
    "print(f\"Scheduler: {Config.LR_SCHEDULER}\")\n",
    "print(f\"Loss function: Dice + Cross Entropy\")\n",
    "print(f\"AMP enabled: {Config.USE_AMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf1496",
   "metadata": {},
   "source": [
    "## 8. Start Training üöÄ\n",
    "\n",
    "**This will take several hours to days depending on your GPU.**\n",
    "\n",
    "Monitor progress via:\n",
    "- Progress bars in this notebook\n",
    "- Training curves: `results/{RUN_NAME}/plots/training_curves.png`\n",
    "- Validation predictions: `results/{RUN_NAME}/plots/val_predictions_epoch_*.png`\n",
    "- Metrics: `results/{RUN_NAME}/metrics/final_metrics.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record start time\n",
    "training_start_time = datetime.now()\n",
    "print(f\"Training started at: {training_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Start training\n",
    "try:\n",
    "    trainer.train(train_loader, val_loader)\n",
    "    \n",
    "    # Record end time\n",
    "    training_end_time = datetime.now()\n",
    "    training_duration = training_end_time - training_start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úì Training Completed Successfully\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Started: {training_start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Ended: {training_end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Duration: {training_duration}\")\n",
    "    print(f\"\\nBest {Config.METRIC_NAME}: {trainer.best_metric:.4f} at epoch {trainer.best_epoch}\")\n",
    "    print(f\"\\nResults saved to: {exp_manager.run_path}\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Training interrupted by user\")\n",
    "    print(f\"Results saved to: {exp_manager.run_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27b885",
   "metadata": {},
   "source": [
    "## 9. Visualize Results\n",
    "\n",
    "Display training curves and final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "from IPython.display import Image, display\n",
    "\n",
    "curves_path = exp_manager.get_plot_path(\"training_curves.png\")\n",
    "if curves_path.exists():\n",
    "    print(\"Training Curves:\")\n",
    "    display(Image(filename=str(curves_path)))\n",
    "else:\n",
    "    print(\"Training curves not available yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca628ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final metrics\n",
    "import json\n",
    "\n",
    "metrics_path = exp_manager.get_metrics_path(\"final_metrics.json\")\n",
    "if metrics_path.exists():\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        final_metrics = json.load(f)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"Final Metrics\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Best Metric: {final_metrics['best_metric']:.4f}\")\n",
    "    print(f\"Best Epoch: {final_metrics['best_epoch']}\")\n",
    "    print(f\"Total Epochs: {final_metrics['total_epochs']}\")\n",
    "    print(f\"Training Time: {final_metrics['training_time_hours']:.2f} hours\")\n",
    "    \n",
    "    # Plot metrics\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    epochs = range(1, len(final_metrics['val_metrics']) + 1)\n",
    "    ax.plot(epochs, final_metrics['val_metrics'], 'o-', linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel(Config.METRIC_NAME, fontsize=12)\n",
    "    ax.set_title('Validation Metric Progress', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=final_metrics['best_metric'], color='r', linestyle='--', alpha=0.5, label=f'Best: {final_metrics[\"best_metric\"]:.4f}')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Final metrics not available yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c8869",
   "metadata": {},
   "source": [
    "## 10. Load Best Model\n",
    "\n",
    "Load the best checkpoint for inference or further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model checkpoint\n",
    "best_checkpoint_path = exp_manager.get_checkpoint_path(\"best_metric_model.pth\")\n",
    "\n",
    "if best_checkpoint_path.exists():\n",
    "    checkpoint = torch.load(best_checkpoint_path)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"Best Model Checkpoint\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"Metrics: {checkpoint['metrics']}\")\n",
    "    print(f\"Timestamp: {checkpoint['timestamp']}\")\n",
    "    \n",
    "    # Load into model\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"\\n‚úì Model weights loaded successfully\")\n",
    "    \n",
    "    # Model is now ready for inference\n",
    "    model.eval()\n",
    "    print(\"‚úì Model set to evaluation mode\")\n",
    "    \n",
    "else:\n",
    "    print(\"Best model checkpoint not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d099b2",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "\n",
    "### For Inference:\n",
    "```python\n",
    "# Load test data\n",
    "test_image = ...  # Load your test NIfTI file\n",
    "\n",
    "# Preprocess (same as training)\n",
    "test_image = preprocess(test_image)\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    prediction = model(test_image.unsqueeze(0).to(Config.DEVICE))\n",
    "    prediction = torch.argmax(prediction, dim=1)\n",
    "\n",
    "# Save prediction\n",
    "save_nifti(prediction, \"output_segmentation.nii.gz\")\n",
    "```\n",
    "\n",
    "### For Ensemble:\n",
    "1. Train multiple models with different seeds/configurations\n",
    "2. Average predictions for better performance\n",
    "3. See documentation for details\n",
    "\n",
    "### For Competition Submission:\n",
    "1. Test on validation set\n",
    "2. Compute final metrics\n",
    "3. Create submission file\n",
    "4. Document approach in `docs/`\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Documentation\n",
    "\n",
    "For detailed explanations of architecture, mathematics, and methodology, see:\n",
    "- `docs/SegMamba_Documentation.md`\n",
    "\n",
    "---\n",
    "\n",
    "**Training Complete! üéâ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
